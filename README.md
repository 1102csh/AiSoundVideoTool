<h1>AI 기반 영상 편집기 [ 2024.04 ~ 2024.06 ]</h1>

<h2>프로젝트 개요</h2>
개발 인원 : 4인
AI 기반 영상 편집기는 사운드 작업 자동화에 초점을 맞춘 영상 편집 도구입니다. <br>
사용자가 영상을 업로드하면 객체 인식, 캡션 생성, 효과음 생성 과정을 거쳐 자동으로 효과음이 삽입된 영상을 제작할 수 있습니다.<br>

<h2>개발 배경</h2>
효과음을 제작하는 폴리 아티스트들은 한 작품의 효과음을 제작하는 데 평균 1개월이라는 오랜 시간이 소요됩니다.<br>
영상 시장이 성장하면서 제작 비용도 증가하고 있으며, 사운드 제작 및 편집 과정에서 발생하는 시간과 비용을 절감할 필요가 있습니다.<br>
이에 AI를 활용하여 효과음을 자동 생성하고 편집하는 기능을 추가하였습니다.<br>

<h2>주요 기능</h2>
<h3>1. 영상 분석 및 효과음 생성</h3>
원본 영상을 프레임 단위로 시퀀스화하고, 객체 인식 후 객체가 등장한 시간을 추출합니다.<br>
추출된 프레임을 기반으로 Image-to-Text 모델을 이용해 캡션을 생성합니다.<br>
생성된 캡션을 활용하여 Text-to-Sound 모델을 통해 객체에 맞는 효과음을 자동으로 생성합니다.<br>
Python의 MoviePy 모듈을 사용하여 효과음이 포함된 1차 결과물을 생성합니다.<br>

<h3>2. 자막 기능</h3>
객체가 인식된 시점의 캡션을 자막으로 제공하며, 사용자가 직접 자막을 추가할 수도 있습니다.<br>
생성된 자막은 타임라인에 표시되어 시간 이동이 가능하며 즉시 확인할 수 있습니다.<br>

<h3>3. 편집 기능</h3>
AJAX 요청 기반의 Flask 서버와 JSON 데이터를 활용하여 타임라인을 구현하였습니다.<br>
타임라인에서 효과음의 위치와 길이를 변경할 수 있으며, 원하는 효과음으로 교체할 수도 있습니다.<br>
원본 영상에서 인식된 객체의 사운드를 API를 통해 제공하며, 필요 시 Text-to-Sound 기능을 활용하여 효과음을 직접 생성할 수도 있습니다.<br>
최종 편집 후 영상 추출 버튼을 통해 편집된 영상을 다운로드할 수 있습니다.<br>

<h2>사용된 AI 모델</h2>
<h3>1. Yolov5 (객체 인식)</h3>
빠른 처리 속도와 높은 인식률을 고려하여 선택하였습니다.<br>
Roboflow 데이터셋과 자체 제작한 커스텀 데이터셋을 사용하여 총 14,109개의 데이터로 학습하였습니다.<br>

<h3>2. Kosmos-2 (캡션 생성)</h3>
Multimodal Large Language Model을 활용하여 이미지 설명 기능을 추가하였습니다.<br>
'주요 객체를 탐지하고 그 객체를 위주로 이미지를 설명해줘'라는 프롬프트를 설정하여 정확도를 높였습니다.<br>

<h3>3. AudioLDM-2 (효과음 생성)</h3>
문맥을 감지할 수 있도록 GPT-2를 활용하여 오디오와 텍스트를 연결합니다.<br>
Image-Description으로 생성된 캡션을 바탕으로 효과음을 생성합니다.<br>

<h2>시스템 구조</h2>
사용자가 영상 파일을 업로드합니다.<br>
영상이 프레임 단위로 분석되며, 객체 인식 및 시간 추출이 이루어집니다.<br>
추출된 프레임을 기반으로 캡션이 생성됩니다.<br>
생성된 캡션을 활용하여 효과음이 자동 생성됩니다.<br>
사용자는 필요에 따라 효과음을 편집할 수 있습니다.<br>
최종적으로 영상이 출력되며 다운로드할 수 있습니다.<br>

<h2>결론</h2>
본 프로젝트는 영상 효과음 제작의 시간과 비용 절감을 목표로 하였으며, AI 모델인 Yolov5, AudioLDM-2, Kosmos-2를 활용하여 자동 효과음 생성 및 편집 기능을 구현하였습니다.<br>

<h2>담당 업무</h2>
* 웹 UI 제작<br>
* 영상 편집 기능 제작
* 자막 생성 기능 및 영상 잘라내기 기능 구현
* 영상 추출 구현

<h2>시연영상</h2>
https://www.youtube.com/watch?v=doqFVXvGheE&list=LL&index=44
